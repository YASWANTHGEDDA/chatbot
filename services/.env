# Service Configuration
DEBUG=True
LLM_SERVICE_PORT=8000

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11435
OLLAMA_MODEL=deepseek-r1
OLLAMA_REQUEST_TIMEOUT=180

# Gemini Configuration
GEMINI_API_KEY=AIzaSyCtb720fH9iySF61ZQkJ7DynsIHkw6k984
# GEMINI_MODEL=gemini-1.5-flash

# Generation Configuration
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=4096
```